# the size of your p matters ... and it doesn't. #

This short post highlights two issues related to p-values, one in which the size of the p-value matters, and the other in which the p-value size doesn't really matter.

In science it is common to define statistical significance as p < 0.05. 

A brief intro on p-values (for my family). It is common to collect scientific data whereby some comparison is made to some baseline, and one wishes to know if the comparative data are different from baseline. For example one might wish to know if people with bladder problems (my area of study) have those problems because of a high baseline bladder pressure. A researcher might collect a series of pressure measurements on say 10 patients with the problem and 10 patients without (we'll call them controls). Then, in sort of backwards logic, one might ask how likely it is that the 10 pressures measured in the patients (1 value per patient), came from the same distribution as the controls. If the probability is high this suggests that there is no difference in pressures, since, roughly speaking, the data from the two sets of patients looks the same. However, if the probability is low, this suggests that in fact the two sets of data are different 

 That on its own is fine despite a push by some to make this criteria more stringent, i.e. to use p < 0.01 (INSERT REFS). In contrast, I tend to prefer being a bit more loose with statistical cutoffs, and weighing the p-value and the data with prior evidence. In other words, a p-value should not be used as an excuse not to think.

The thing that really drives me nuts is the statistically significant p-value which is only reported as being less than the specified cutoff for significance. For example, a paper will say that p < 0.05 is considered statistically significant, and then a result will be identified as being "statistically significant" with no further data given. From the paper's definition, we know that the p-value is less than 0.05, but by how much? This is where the size of the p-value matters. 

TODO: insert graphs showing this ... 

is not-uncommon to see statistical significance defined as a p < 0.05, a

Ukimura et al. 2004 p < 0.05 5 Hz, 2000 Hz.